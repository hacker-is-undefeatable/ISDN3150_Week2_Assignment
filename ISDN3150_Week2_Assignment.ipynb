{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part4: Assignment: From Image to Text — Understanding Visual Content with Language Models\n",
    "\n",
    "### Objective\n",
    "\n",
    "The goal of this assignment is to explore how visual information can be represented in textual form and how large language models (LLMs) can reason about such representations.  \n",
    "You will convert a personal image into a text-based (ASCII-style) image and investigate whether a language model can understand and describe the visual content from the textual representation alone.\n",
    "\n",
    "---\n",
    "\n",
    "### Task Description\n",
    "\n",
    "#### Step 1: Image Acquisition\n",
    "\n",
    "- Capture or generate an image of yourself.\n",
    "  - You may use a photograph, a self-portrait, or an AI-generated image that represents you.\n",
    "- The image should clearly show a human face or upper body.\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 2: Image-to-Text Conversion\n",
    "\n",
    "- Convert the image into a **text-based image representation** (e.g., ASCII art).\n",
    "- The conversion should:\n",
    "  - Use a fixed-width (monospace) font.\n",
    "  - Preserve basic visual structure such as contours, shading, or facial features.\n",
    "- You may use Python with any library (e.g., Python with PIL, OpenCV).\n",
    "\n",
    "Below is an example:\n",
    "\n",
    "![Input Image](imgs/image.png)\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 3: Language Model Interpretation\n",
    "\n",
    "- Provide the text-based image as input to a language model.\n",
    "- Ask the model to:\n",
    "  - Describe what it sees in the text representation.\n",
    "  - Infer high-level attributes (e.g., whether it looks like a face, a person, or an object).\n",
    "- Record the model’s response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@WW$_____.....__~~~~^~~(~^^C`~#E[XOO$@@@@@@@@@\n",
      "@@@@@WW(__......___~~^~?==??~_^/=~_^XEOEWW@@@@@@@@\n",
      "@@@@@WW~~__...._____~~?=~~^^~/~~X~~_=(OOCC#@@@@@@@\n",
      "@@@@@WW~~~__._.____~.=^^_~^~=X~^~CX^~[CO$OOX@@@@@@\n",
      "@@@@@WW~~~___.__...____~^==^/E_[[^CX(~XXECE=@@@@@@\n",
      "@@@@@WO~^^~__/__..__.__~_~/^==^C(=#[?(^EEEXO@@@@@@\n",
      "@@@@@@W~~^~~~^^....__~__~(/?[(=$[X=EE(~/EEWE#@@@@@\n",
      "@@@@@WW[~^[^~(______^^==~^/(?C?XXC(##X[?/E$O$#@@@@\n",
      "@@@@@WW#^=[~~~___~COE~^=~^^^=[?XOCX[O#X^/XXE#W#@@@\n",
      "@@@@@WWW=^/^~~~~~^[^=$W$C=?(XCC?$EXE$#$C^(EEW$##@@\n",
      "@@@@@WWW~^^^^=~~~^=^OWW/[==/X(XX#XEXC$#X^/[[XEW#@@\n",
      "@@@@WW@O^^=/[??^^=/[=^~=__=CCO(X#$CXXC##/~CX#WOWW@\n",
      "@@@@W@WO^^?EO/[=~~==^^~___=[EXEEO$EC[E##$^(CCW$WW@\n",
      "@@@@@W@C~^[(=^C(~_~__~~___~[CEOO$WOXC/C$$/~XXW#@@#\n",
      "@@@WWWWC~?[E#W@~~_~______~~/OXE#[[#XC/?(EX^CXC@WW[\n",
      "WWW@WW#C=^?#O(=~~_~~_____~~=CO#$E#W$C??=/E=(XC$O#(\n",
      "WWW@WWW[=?/O/=^~~~~^~____~^?XX#$$WWOOC?==C?^EXO$OC\n",
      "WWW@W#W(??[X=^~~~~^^=~~~~^=?[(OW$$$$CC==^(O=XEC$X@\n",
      "WWWWWWE=//C[?~~~~~^=X~~~~^=([X$WWCW$C(=^^/CEEEEE/@\n",
      "WWWWWW$C((X(E~~~=CO$#~~~^=?[CO#$WWW#O??^~?EECOECOW\n",
      "WWWWW#$(/[X[#^~~EOO^~~~^=?(CC$XO#WOEO[==~?EX[$EEO#\n",
      "WWWWW#O=/CX[$^~~^C^^^^=/?/[XE$W##WE##X^=^?OOE$OOEW\n",
      "WWWWW$??(CC[$#^^^^=XOOOO[[XOO##E$W@#$C/=^[O$$#$OXO\n",
      "WWWW#O/^[CC[$#[^^(XO#CC?(CX$$##W#OWX@O(==[$$#O$OE$\n",
      "===^^C[?[C([O$$==[E[(EX(([E$#####W#X@$[=?CO#WO$OX$\n",
      "==^=?^^=CC([E$$O=?[[EEC/(CO#####WEE@E@[((CE@W$$OXO\n",
      "==^^^=^=?C([XO$OE/?[CC=?[X$######W$EXW[[[XEWW#OOXO\n",
      "_.__~^=?^^/CXEOCXC/?==?[XO$#$########$XX[X$#WW$EXE\n",
      "_..___.~^==CXXE?C(X[?(CEO$$$$######=EOOECEEOWW#XCX\n",
      "_________===(XX?[(COXCXEOOO$$$$#####$$$CXOOO#W#OX[\n",
      "...______._?([[=[([CCE$##OOO$$$$####$X?OXE$$$#W#EC\n",
      "........_._~=(==(([=CEE$##$O$$$$$#$$OOOXXE#O##W#$[\n",
      "............^^^==((/EEEO$#$$O$$$$$$OEEXEXEO#OW$#OE\n",
      "........`.`..~^^?//(COEEO$#$O$$$$OOXXEO^OEE$#O##O#\n",
      ".....````````_~^?/=[EXEXEO#$OOOOOEXCCC[XXEXO$W$##$\n",
      "......````````~^//?[ECX[[E##$OOEEXC[[([XXE$EE#####\n",
      ".....`````````~/[[(=EC([/X$#OOEXCC[[//C(((EOOOE$##\n",
      "`....`````````./C//C=C(((X$OOXC[((//C=?///?X$O$##$\n",
      "`...``````````.?(C?/?CC([X$C//??CCX[?=??//??//XE$W\n",
      "`..``````````.`^([(?[CC[[E$[[/C[(([C(((////=CX^???\n",
      "```.```````````?^[C[C[XC[OX[C(???//??/?/(//=/??X==\n",
      "```````````````/[=[[((XX[OC[/??=???????//?=?^=[=?=\n",
      "`````.```````..?(??[?(XE[EC(/????????/((//^^~^(?==\n",
      "`````````....`.?/C^[?[XX[XC[//??????//(//?=~==[?=?\n",
      "````````......~??E=((CXX[XX[((//////(((((?^(==C???\n",
      "```..````...../=X((([EXX[EEC[((////(((((///==?X=/[\n",
      ".``..```.....`?//?C/CEEXCXO[((/(/((((((((=/?=/C//(\n",
      "``...```.....~^==/[/COOXCC(/(^=(((((([((??/??/X/([\n",
      "~~.`.........^^^=(((C$EXC[====((===?(??/==?=?(X/([\n",
      "^=^_......._^^^=^XC[E$EXE(==[(///==[CCX(=CX=/(E/(C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "CHARS = '@W#$OEXC[(/?=^~_.` '\n",
    "\n",
    "\n",
    "def mono(input_img, target_h=100, target_w=100):\n",
    "    \"\"\"\n",
    "    input_img: an image of shape [h, w], which should be an numpy array\n",
    "    target_h: target height of the generated str-based image.\n",
    "    target_w: target width of the generated str-based image.\n",
    "    \n",
    "    Note:\n",
    "        1) that you may not want to generate an image of an extremely large size.\n",
    "        2) so implement this, you may need to resize the image using the resize function from cv2 library\n",
    "        3) you may need to keep the aspect ratio when giving target_h and target_w\n",
    "\n",
    "    return:\n",
    "        a text representing an image\n",
    "    \"\"\"\n",
    "    # Todo 1: implement your code here\n",
    "    # Get original dimensions\n",
    "    h, w = input_img.shape\n",
    "    \n",
    "    # Calculate aspect ratio and resize while maintaining aspect ratio\n",
    "    aspect_ratio = w / h\n",
    "    if aspect_ratio > target_w / target_h:\n",
    "        # Width is the constraint\n",
    "        new_w = target_w\n",
    "        new_h = int(target_w / aspect_ratio)\n",
    "    else:\n",
    "        # Height is the constraint\n",
    "        new_h = target_h\n",
    "        new_w = int(target_h * aspect_ratio)\n",
    "    \n",
    "    # Resize the image\n",
    "    resized_img = cv2.resize(input_img, (new_w, new_h))\n",
    "\n",
    "    # Equalize histogram to improve contrast\n",
    "    resized_img = cv2.equalizeHist(resized_img)\n",
    "    \n",
    "    # Normalize pixel values to 0-255 range\n",
    "    resized_img = (resized_img - resized_img.min()) / (resized_img.max() - resized_img.min() + 1e-5) * 255\n",
    "    resized_img = resized_img.astype(np.uint8)\n",
    "    \n",
    "    # Map pixel values to characters\n",
    "    ascii_art = \"\"\n",
    "    for row in resized_img:\n",
    "        for pixel in row:\n",
    "            # Map pixel brightness (0-255) to character index (0 to len(CHARS)-1)\n",
    "            char_idx = int((pixel / 255) * (len(CHARS) - 1))\n",
    "            ascii_art += CHARS[char_idx]\n",
    "        ascii_art += \"\\n\"\n",
    "    \n",
    "    return ascii_art\n",
    "\n",
    "\n",
    "# Todo 2: read your image here\n",
    "url = \"https://github.com/hacker-is-undefeatable/ISDN3150_Week2_Assignment/blob/main/imgs/459838642_879823690765993_7978852413075077763_n.jpg?raw=true\"\n",
    "\n",
    "# Download and read the image from URL\n",
    "response = requests.get(url)\n",
    "im = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Convert PIL image to numpy array\n",
    "im = np.array(im)\n",
    "\n",
    "# Convert to grayscale if it is an RGB/RGBA image\n",
    "if len(im.shape) == 3:\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Convert this to string art\n",
    "ascii_art = mono(im, target_h=50, target_w=100)\n",
    "print(ascii_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Description of the Observation**:\n",
      "   The ASCII art is quite complex and appears to be a dense arrangement of various characters, predominantly \"@\" and \"W\", with other symbols including $, #, C, O, E, and X. The overall composition has a structured form, implying a recognizable pattern or image. There are sections that seem to flow or wave with a certain rhythm, creating a dynamic visual.\n",
      "\n",
      "2. **Inference of the Object or Subject**:\n",
      "   This text-based image appears to represent a vaguely organic or abstract form, possibly resembling a plant-like structure, landscape, or a stylized depiction of a wave or movement of water. The characters seem to create a sense of fluidity and variation in shape, indicating a natural element rather than something mechanical or geometric.\n",
      "\n",
      "3. **Visible Features or Characteristics**:\n",
      "   - The presence of various symbols suggests different shades or depths, resembling a textured surface.\n",
      "   - The use of \"@\" could indicate a solid or foundational aspect of the design, possibly representing leaves or a broad surface.\n",
      "   - Other characters like \"C\", \"$\", and \"E\" appear in clusters and may refer to finer details, reminiscent of foliage or rippling water.\n",
      "   - Variations in spacing and character choice create a sense of movement or flow, enhancing the organic feel of the image.\n",
      "   - Sections such as the upper and lower areas have a more chaotic arrangement, which could symbolize turbulence or the dynamic nature of water or wind.\n",
      "\n",
      "Overall, while it is open to interpretation, the representation leans towards capturing the essence of fluidity and nature rather than depicting a clear, identifiable object.\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-10-21\",\n",
    "    azure_endpoint=\"https://hkust.azure-api.net\"\n",
    ")\n",
    "\n",
    "# Todo 3: Put your text-based image here to test whether the LLM can understand your string art or not.\n",
    "prompt_content = f\"\"\"Please analyze the following text-based image representation and describe what you see:\n",
    "\n",
    "{ascii_art}\n",
    "\n",
    "Based on this ASCII art representation, can you:\n",
    "1. Describe what you observe in the text-based image\n",
    "2. Infer what type of object or subject this represents (e.g., face, person, landscape)\n",
    "3. Identify any visible features or characteristics\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that can analyze text-based image representations and understand visual content from ASCII art.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt_content\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
